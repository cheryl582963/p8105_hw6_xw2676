---
title: "p8105_hw6_xw2676"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      fig.width = 8,
                      fig.height = 6,
                      out.width = "90%")
library(tidyverse)
library(ggridges)
library(rvest)
library(modelr)
library(mgcv)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## load and tidy the data

```{r}
birthweight = read_csv("./dataset/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(
    babysex = factor(as.factor(babysex), levels = c(1,2), labels = c("male", "female")),
    frace = factor(as.factor(frace), levels = c(1,2,3,4,8,9), labels = c("white", "black", "asian", "puerto_rican", "other", "unknown")),
    malform = factor(as.factor(malform), levels = c(0,1), labels = c("absent", "present")),
    mrace = factor(as.factor(mrace), levels = c(1,2,3,4,8,9), labels = c("white", "black", "asian", "puerto_rican", "other", "unknown"))
  )
```

## Problem1

### Propose a regression model for birthweight. 

I'd like to build the model by the following steps. First add all variables to the model, use test to check the significance of the variables, and then delete the variables that are not significant. 

```{r}
## add total variables as predictors
fit1_1 = lm(bwt~babysex+bhead+blength+delwt+fincome+frace+gaweeks+malform+menarche+mheight+momage+mrace+parity+pnumlbw+pnumsga+ppbmi+ppwt+smoken+wtgain, data = birthweight)
## use anova to check significance of every variable
summary(fit1_1)
## delete variables that are not significant(fincome, frace, malform, menarche, mheight, momage, mrace, pnumlbw, pnumsga, ppbmi, ppwt, wtgain)
fit1 = lm(bwt~babysex+bhead+blength+delwt+gaweeks+parity+smoken, data = birthweight)
## check again
summary(fit1)
## done!
birthweight_model = modelr::add_residuals(birthweight, fit1) %>% 
  modelr::add_predictions(., fit1) 
ggplot(aes(x = pred, y = resid), data = birthweight_model) +
  geom_point() +
  geom_smooth(method = lm) +
labs(
  x = "fitted values",
  y = "residuals",
  title = "model residuals against fitted values"
) +
 geom_hline(yintercept = 0,col = "red",linetype = "dashed")
```

### Compare your model to two other

```{r}
fit2 = lm(bwt~blength+gaweeks, data = birthweight)
summary(fit2)
fit3 = lm(bwt~bhead+blength+babysex+bhead*blength+blength*babysex+babysex*bhead+bhead*blength*babysex, data = birthweight)
summary(fit3)
cv_df = crossv_mc(birthweight, 100)
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df = 
  cv_df %>% 
  mutate(fit1  = map(train, ~lm(bwt~babysex+bhead+blength+delwt+gaweeks+parity+smoken, data = .x)),
         fit2  = map(train, ~lm(bwt~blength+gaweeks, data = .x)),
         fit3  = map(train, ~lm(bwt~bhead+blength+babysex+bhead*blength+blength*babysex+babysex*bhead+bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_fit1 = map2_dbl(fit1, test, ~rmse(model = .x, data = .y)),
         rmse_fit2 = map2_dbl(fit2, test, ~rmse(model = .x, data = .y)),
         rmse_fit3 = map2_dbl(fit3, test, ~rmse(model = .x, data = .y)))
cv_df_rmse = cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) 
cv_df_rmse %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin() +
labs(
  x = "model",
  y = "rmse",
  title = "prediction error distributions of each model"
) 
cv_df_rmse %>% 
  group_by(model) %>% 
  summarise(
    mean_rmse = mean(rmse)
  ) %>% 
  knitr::kable(format = "html", align = 'c')
```

According to the plot and table above, we can see that the rmse of the model 1 is superior than the other two model. 

## Problem 2

```{r}
set.seed(10)
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
set.seed(10)
boot_weather = weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results_1 = map(models, broom::tidy),
    results_2 = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  mutate(
    log_b0_b1 = map_dbl(results_1, ~.x %>% pull(estimate) %>% prod %>% log),
    r_squared = map_dbl(results_2, ~.x %>% pull(r.squared) )
  ) 

ggplot(aes(x = log_b0_b1), data = boot_weather) +
  geom_density(fill = "lightblue") +
  labs(
    x = expression("log("~hat(beta)[0]~"*"~hat(beta)[1]~")"),
    title = expression("Distribution of log("~hat(beta)[0]~"*"~hat(beta)[1]~")")
  )

ggplot(aes(x = r_squared), data = boot_weather) +
  geom_density(fill = "lightblue") +
  labs(
    x = expression(""~r^2~""),
    title = expression("Distribution of "~r^2~""))
```

According to the plot, we can see that the distribution of r_square and log_b0_b1 are slightly left-skewed normal distribution.


```{r}
r_square_interval = quantile(pull(boot_weather, r_squared), c(0.025,0.975))
log_b0_b1_interval = quantile(pull(boot_weather, log_b0_b1), c(0.025,0.975))
rbind(r_square_interval, log_b0_b1_interval) %>% 
  knitr::kable(format = "html", align = 'c', caption = "95% confidence interval for estimates")
```

















